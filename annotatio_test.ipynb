{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import pandas as pd\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL.Image import Image\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_file(label_path: str) -> pd.DataFrame:\n",
    "    with open(label_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    attributes = pd.Series(data[\"attributes\"])\n",
    "    boxes = pd.DataFrame(list(map(lambda d: d[\"box2d\"], data[\"labels\"])))\n",
    "    categories = pd.Series(list(map(lambda d: d[\"category\"], data[\"labels\"])))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"category\": categories,\n",
    "            \"x1\": boxes.x1,\n",
    "            \"x2\": boxes.x2,\n",
    "            \"y1\": boxes.y1,\n",
    "            \"y2\": boxes.y2,    \n",
    "        },\n",
    "    )\n",
    "    for (key, val) in attributes.items():\n",
    "        df[key] = val\n",
    "    df[\"image_id\"] = label_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import open as pil_open\n",
    "\n",
    "def label_str_to_num(label: str) -> int:\n",
    "    return int(label[0])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data: List[str], labels: List[str] = None, transform: torchvision.transforms.Compose = None, has_label: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.has_label = has_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        image_path = self.data[index]\n",
    "        img = pil_open(image_path).convert(\"RGB\")\n",
    "        # width_ratio = config.input_size[1] / img.size[1]\n",
    "        # height_ratio = config.input_size[0] / img.size[0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        if not self.has_label:\n",
    "            return img, {}\n",
    "        label_info = parse_json_file(self.labels[index])\n",
    "        label = torch.tensor(np.array(list(map(label_str_to_num, label_info.category.values)))).squeeze(dim=0)\n",
    "        boxes = [label_info.x1.values, label_info.y1.values, label_info.x2.values, label_info.y2.values]\n",
    "        # for i in range(len(boxes)):\n",
    "        #     ratio = width_ratio if i % 2 == 0 else height_ratio\n",
    "        #     boxes[i] = list(map(lambda d: d * ratio, boxes[i]))\n",
    "        boxes = torch.tensor(np.array(boxes)).squeeze(dim=0).T        \n",
    "        image_id = label_info[\"image_id\"].values[0]\n",
    "        return img, {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": label\n",
    "        }, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6431, 0.6471, 0.6510,  ..., 0.6275, 0.6314, 0.6196],\n",
       "          [0.6471, 0.6510, 0.6549,  ..., 0.6235, 0.6275, 0.6157],\n",
       "          [0.6392, 0.6392, 0.6431,  ..., 0.6314, 0.6314, 0.6235],\n",
       "          ...,\n",
       "          [0.6353, 0.6353, 0.6275,  ..., 0.6392, 0.6431, 0.6392],\n",
       "          [0.6392, 0.6314, 0.6353,  ..., 0.6314, 0.6353, 0.6353],\n",
       "          [0.6353, 0.6275, 0.6392,  ..., 0.6353, 0.6431, 0.6471]],\n",
       " \n",
       "         [[0.6431, 0.6471, 0.6510,  ..., 0.6314, 0.6353, 0.6235],\n",
       "          [0.6471, 0.6510, 0.6549,  ..., 0.6275, 0.6314, 0.6196],\n",
       "          [0.6392, 0.6392, 0.6431,  ..., 0.6353, 0.6353, 0.6275],\n",
       "          ...,\n",
       "          [0.6431, 0.6431, 0.6353,  ..., 0.6392, 0.6431, 0.6392],\n",
       "          [0.6471, 0.6392, 0.6431,  ..., 0.6314, 0.6353, 0.6353],\n",
       "          [0.6431, 0.6353, 0.6471,  ..., 0.6353, 0.6431, 0.6471]],\n",
       " \n",
       "         [[0.6353, 0.6392, 0.6431,  ..., 0.6118, 0.6157, 0.6039],\n",
       "          [0.6392, 0.6431, 0.6471,  ..., 0.6078, 0.6118, 0.6000],\n",
       "          [0.6314, 0.6314, 0.6353,  ..., 0.6157, 0.6157, 0.6078],\n",
       "          ...,\n",
       "          [0.6314, 0.6314, 0.6235,  ..., 0.6314, 0.6353, 0.6314],\n",
       "          [0.6353, 0.6275, 0.6235,  ..., 0.6235, 0.6275, 0.6275],\n",
       "          [0.6314, 0.6235, 0.6275,  ..., 0.6275, 0.6353, 0.6392]]]),\n",
       " {'boxes': tensor([[ 804,   63, 1519, 1004]]), 'labels': tensor(1)},\n",
       " 'train_2570037_0045')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [os.path.join(os.getcwd(), \"train_images/train_2570037_0045.jpg\")]\n",
    "labels = [os.path.join(os.getcwd(), \"train_annotations/train_2570037_0045.json\")]\n",
    "\n",
    "dataset = CustomDataset(data=data, labels=labels, has_label=True)\n",
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
