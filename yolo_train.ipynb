{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/venv/bin/pip\n",
      "/workspace/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which pip\n",
    "!which python\n",
    "# !pip install numpy torch scikit-learn tqdm\n",
    "# !pip install pandas ultralytics matplotlib torchvision IPython opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch.distributed as dist\n",
    "import pandas as pd\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL.Image import Image\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageDraw\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/workspace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.59 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.13 torch-2.0.0+cu117 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=modern_book.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/workspace/runs/detect/train4\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.Conv                  [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.Conv                  [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.C2f                   [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.Conv                  [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.C2f                   [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.Conv                  [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.C2f                   [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.C2f                   [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.SPPF                  [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.C2f                   [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.Conv                  [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.C2f                   [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8727598  ultralytics.nn.modules.Detect                [10, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68162238 parameters, 68162222 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/train/mordern/labels... 818 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 818/818 [00:01<00:00, 657.56it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspace/train/mordern/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/val/mordern/labels... 252 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 252/252 [00:00<00:00, 695.97it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspace/val/mordern/labels.cache\n",
      "Plotting labels to /workspace/runs/detect/train4/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/runs/detect/train4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      13.7G      2.177      2.606      1.533        116        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:34<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.33it/s]\n",
      "                   all        252       9569       0.53      0.343      0.325      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      14.2G      1.668      1.282      1.182         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.33it/s]\n",
      "                   all        252       9569      0.492      0.529      0.496      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      14.2G      1.649      1.249      1.125        111        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.36it/s]\n",
      "                   all        252       9569      0.629      0.568      0.641        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      14.2G      1.685      1.236      1.124         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.37it/s]\n",
      "                   all        252       9569      0.724      0.561      0.552      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      14.2G      1.613      1.116      1.111        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.38it/s]\n",
      "                   all        252       9569      0.548      0.673      0.643       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      14.2G      1.489     0.9683      1.049        153        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.39it/s]\n",
      "                   all        252       9569      0.723      0.663      0.731       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      14.2G      1.336     0.8606      1.008        116        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.39it/s]\n",
      "                   all        252       9569      0.694      0.597      0.627      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      14.2G      1.197     0.7817     0.9732         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.38it/s]\n",
      "                   all        252       9569       0.85      0.603      0.733      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      14.2G      1.106     0.7211     0.9526         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:05<00:00,  1.38it/s]\n",
      "                   all        252       9569      0.774      0.625      0.702      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      14.2G      1.039     0.6729     0.9378         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:33<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.69s/it]\n",
      "                   all        252       9569       0.78      0.667        0.7      0.511\n",
      "\n",
      "10 epochs completed in 0.123 hours.\n",
      "Optimizer stripped from /workspace/runs/detect/train4/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from /workspace/runs/detect/train4/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating /workspace/runs/detect/train4/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.13 torch-2.0.0+cu117 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "Model summary (fused): 268 layers, 68133198 parameters, 0 gradients, 257.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.72s/it]\n",
      "                   all        252       9569      0.724      0.663      0.731       0.53\n",
      "             1_overall        252        252      0.987      0.992      0.995       0.94\n",
      "        4_illustration        252        134      0.831      0.694      0.799      0.428\n",
      "               5_stamp        252         15      0.869        0.6      0.704      0.624\n",
      "            6_headline        252        375      0.415      0.288      0.288      0.173\n",
      "             7_caption        252        132      0.933      0.211      0.572      0.285\n",
      "            8_textline        252       8659      0.522      0.855      0.764      0.368\n",
      "               9_table        252          2      0.508          1      0.995      0.895\n",
      "Speed: 0.6ms preprocess, 9.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/runs/detect/train4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "modern_model = YOLO(\"yolov8x.pt\")\n",
    "modern_model.train(data=\"modern_book.yaml\", epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.59 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.13 torch-2.0.0+cu117 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=old_book.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/workspace/runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.Conv                  [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.Conv                  [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.C2f                   [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.Conv                  [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.C2f                   [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.Conv                  [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.C2f                   [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.C2f                   [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.SPPF                  [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.C2f                   [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.Conv                  [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.C2f                   [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8727598  ultralytics.nn.modules.Detect                [10, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68162238 parameters, 68162222 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/train/old/labels... 1014 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1014/1014 [00:01<00:00, 763.42it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspace/train/old/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/val/old/labels... 205 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 205/205 [00:00<00:00, 746.10it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspace/val/old/labels.cache\n",
      "Plotting labels to /workspace/runs/detect/train6/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/runs/detect/train6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      14.2G      1.633      2.066      1.406         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.16it/s]\n",
      "                   all        205       4452      0.695      0.554      0.554      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      14.2G      1.177      1.049      1.063        146        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                   all        205       4452      0.797      0.668      0.689      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      14.2G      1.247       1.06      1.056        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                   all        205       4452      0.769      0.653      0.699        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      14.2G      1.168     0.9204      1.025        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                   all        205       4452      0.697      0.634      0.674      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      14.2G      1.113     0.8491     0.9873         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                   all        205       4452      0.846      0.734       0.79      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      14.2G      1.085     0.7584     0.9662        162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                   all        205       4452      0.833      0.727      0.762      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      14.2G      0.987     0.6689     0.9366         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                   all        205       4452      0.869      0.747      0.805      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      14.2G      0.939     0.6028     0.9111        123        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.18it/s]\n",
      "                   all        205       4452      0.917      0.758      0.826       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      14.2G     0.8945     0.5522      0.899        150        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.19it/s]\n",
      "                   all        205       4452      0.888      0.774      0.838      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      14.2G     0.8418     0.5118     0.8851        115        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.97s/it]\n",
      "                   all        205       4452      0.893       0.79      0.843      0.643\n",
      "\n",
      "10 epochs completed in 0.149 hours.\n",
      "Optimizer stripped from /workspace/runs/detect/train6/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from /workspace/runs/detect/train6/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating /workspace/runs/detect/train6/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.13 torch-2.0.0+cu117 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "Model summary (fused): 268 layers, 68133198 parameters, 0 gradients, 257.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.97s/it]\n",
      "                   all        205       4452      0.893      0.791      0.843      0.643\n",
      "             1_overall        205        205      0.992      0.995      0.995      0.993\n",
      "         2_handwritten        205       2036      0.799      0.826      0.847      0.477\n",
      "          3_typography        205       1917      0.911      0.665      0.829      0.565\n",
      "        4_illustration        205        218      0.872      0.654      0.691       0.57\n",
      "               5_stamp        205         76      0.891      0.816      0.853      0.609\n",
      "Speed: 0.8ms preprocess, 9.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/runs/detect/train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "old_model = YOLO(\"yolov8x.pt\")\n",
    "old_model.train(data=\"old_book.yaml\", epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
